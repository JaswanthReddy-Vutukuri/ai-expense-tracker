# AI Orchestrator: Custom vs Framework Architecture Analysis

**Project**: AI Expense Tracker  
**Analysis Date**: February 8, 2026  
**Purpose**: Map existing custom implementation to LangChain/LangGraph/LangSmith concepts

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Existing Architecture Overview](#existing-architecture-overview)
3. [Execution Flows](#execution-flows)
4. [Custom ‚Üí Framework Mapping](#custom--framework-mapping)
5. [Component Deep Dive](#component-deep-dive)
6. [Safety & Production Patterns](#safety--production-patterns)
7. [Migration Strategy](#migration-strategy)

---

## Executive Summary

The existing **ai/** orchestrator implements a **production-grade, custom AI system** with:

- ‚úÖ **Intent-based routing** (lightweight agent pattern)
- ‚úÖ **MCP tool execution** (validated, deterministic)
- ‚úÖ **Full RAG pipeline** (ingest, chunk, embed, retrieve, generate)
- ‚úÖ **Bi-directional reconciliation** (PDF ‚Üî App sync)
- ‚úÖ **Production safety** (timeouts, retries, validation, logging)
- ‚úÖ **User isolation** (multi-tenant ready)
- ‚úÖ **Cost controls** (rate limiting, token limits)

**Key Philosophy**: 
- LLM for intent understanding and generation
- Deterministic code for business logic
- No LLM in critical financial decisions
- Additive-only reconciliation (never auto-delete)

---

## Existing Architecture Overview

### High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         FRONTEND (Angular)                       ‚îÇ
‚îÇ                    DO NOT MODIFY - Out of Scope                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      AI ORCHESTRATOR (ai/)                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ  server.js (Express + Security + Rate Limiting)             ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚îÇ                                       ‚îÇ
‚îÇ                           ‚ñº                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ  /ai/chat Route (authMiddleware + traceId + validation)    ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚îÇ                                       ‚îÇ
‚îÇ                           ‚ñº                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ  Intent Router (LLM-based classification)                   ‚îÇ ‚îÇ
‚îÇ ‚îÇ  - TRANSACTIONAL: CRUD operations                           ‚îÇ ‚îÇ
‚îÇ ‚îÇ  - RAG_QA: Question answering from PDFs                     ‚îÇ ‚îÇ
‚îÇ ‚îÇ  - RAG_COMPARE: PDF vs App diff                             ‚îÇ ‚îÇ
‚îÇ ‚îÇ  - SYNC_RECONCILE: Bi-directional sync workflow             ‚îÇ ‚îÇ
‚îÇ ‚îÇ  - CLARIFICATION: Ambiguous/out-of-scope                    ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚îÇ                                       ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ              ‚ñº            ‚ñº            ‚ñº             ‚ñº           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇTransactional ‚îÇ ‚îÇ RAG QA   ‚îÇ ‚îÇRAG Compare‚îÇ ‚îÇSync/Reconcile‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Handler    ‚îÇ ‚îÇ Handler  ‚îÇ ‚îÇ  Handler  ‚îÇ ‚îÇ   Handler    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ         ‚îÇ              ‚îÇ             ‚îÇ               ‚îÇ           ‚îÇ
‚îÇ         ‚ñº              ‚ñº             ‚ñº               ‚ñº           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ              LLM Agent (Tool Calling)                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - OpenAI function calling                               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Max iterations: 5                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Timeout: 60s                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - System prompt + tool definitions                      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                          ‚îÇ                                       ‚îÇ
‚îÇ                          ‚ñº                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ              MCP Tool Registry                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - create_expense                                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - list_expenses                                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - modify_expense                                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - delete_expense                                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - clear_expenses                                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Each tool:                                              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚úì Validates arguments                                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚úì Wraps backend API call                               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚úì Handles errors                                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚úì Logs execution                                       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                          ‚îÇ                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      BACKEND (Node.js + SQLite)                  ‚îÇ
‚îÇ                    DO NOT MODIFY - Out of Scope                  ‚îÇ
‚îÇ  - /api/expenses (CRUD endpoints)                                ‚îÇ
‚îÇ  - JWT auth                                                      ‚îÇ
‚îÇ  - User isolation                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### RAG Pipeline Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        RAG PIPELINE                              ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  INGESTION (Upload Flow):                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ 1. PDF Upload (/ai/upload)                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Üì                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 2. Extract Text (pdf-parse)                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Üì                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 3. Chunk Text (semantic + size-based chunking)             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    - Max: 500 tokens                                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    - Overlap: 50 tokens                                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Üì                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 4. Generate Embeddings (text-embedding-ada-002)            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    - Batch processing                                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    - Timeout: 15s per batch                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Üì                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 5. Store in Vector DB (in-memory + disk persistence)       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    - User isolation built-in                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    - File: data/vector-store.json                          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  RETRIEVAL (Query Flow):                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ 1. User Query                                              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Üì                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 2. Generate Query Embedding                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Üì                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 3. Cosine Similarity Search                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    - Top K: 5 chunks (configurable)                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    - User-filtered                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Üì                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 4. Context Assembly                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚Üì                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 5. LLM Generation (RAG prompt)                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    - Answer with citations                                 ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Reconciliation Workflow Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            SYNC/RECONCILE WORKFLOW (Multi-Stage)                 ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Stage 1: COMPARE                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Extract PDF expenses from vector store                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Fetch App expenses via backend API                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Normalize dates, amounts, categories                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Compute diff:                                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - matched: Expenses in both (same amount+date)          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - pdf_only: In PDF but not in app                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - app_only: In app but not in PDF                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Return structured diff (NOT LLM explanation)             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ  Stage 2: PLAN (Deterministic - NO LLM)                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Validate each expense (amount, date, description)        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Apply business rules:                                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Min amount: ‚Çπ1                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Max auto-sync: ‚Çπ10,000                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - No duplicates                                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Generate TWO-SIDED plan:                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - to_app: pdf_only ‚Üí add to app via MCP                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - to_pdf: app_only ‚Üí add to regenerated PDF             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ ADDITIVE-ONLY (never auto-delete)                        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ  Stage 3: VALIDATE                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Check prerequisites:                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - User has uploaded PDFs                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Plan is non-empty                                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Auth token valid                                       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ  Stage 4: EXECUTE                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Execute plan via MCP tools:                              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Call create_expense for each to_app item              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Log success/failure for each                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Collect execution results                                ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ  Stage 5: REPORT                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Generate downloadable expense report (HTML/CSV)          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Include:                                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Synced expenses                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Summary statistics                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Timestamp & user ID                                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Save to data/reports/                                    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                          ‚Üì                                       ‚îÇ
‚îÇ  Stage 6: RESPOND                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Return natural language summary:                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - "Synced X expenses to app"                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - "Report available at: [URL]"                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   - Error handling if partial failure                      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Execution Flows

### Flow 1: Transactional Expense Operation

```
User: "Add ‚Çπ500 for lunch today"
  ‚Üì
[/ai/chat] ‚Üí Auth + Validation + TraceID
  ‚Üì
[Intent Router] ‚Üí Classify ‚Üí TRANSACTIONAL
  ‚Üì
[Transactional Handler] ‚Üí processChatMessage()
  ‚Üì
[LLM Agent] ‚Üí Parse intent + Generate tool call
  ‚Üì
  Tool Call: create_expense({
    amount: 500,
    category: "Food",
    description: "lunch",
    date: "2026-02-08"
  })
  ‚Üì
[MCP Tool Registry] ‚Üí Validate args
  ‚Üì
[Backend Client] ‚Üí POST /api/expenses
  ‚Üì
[Backend DB] ‚Üí Insert expense record
  ‚Üì
[Response] ‚Üê "‚úÖ Added ‚Çπ500 for Food on 2026-02-08"
```

**Key Points**:
- LLM extracts structured args from natural language
- MCP tool validates and executes
- Backend handles persistence
- Single request-response cycle

---

### Flow 2: RAG Question Answering

```
User: "What did I spend on groceries in my bank statement?"
  ‚Üì
[/ai/chat] ‚Üí Auth + Validation + TraceID
  ‚Üì
[Intent Router] ‚Üí Classify ‚Üí RAG_QA
  ‚Üì
[RAG QA Handler]
  ‚Üì
  [1. Query Embedding]
    - Generate embedding for "groceries spending bank statement"
  ‚Üì
  [2. Vector Search]
    - Cosine similarity against stored chunks
    - Filter by userId
    - Top 5 chunks retrieved
  ‚Üì
  [3. Context Assembly]
    - Format chunks with [Source 1], [Source 2], etc.
  ‚Üì
  [4. LLM Generation]
    - RAG prompt: "Answer based ONLY on context"
    - Include citations
  ‚Üì
[Response] ‚Üê "Based on your bank statement [Source 1], you spent ‚Çπ3,450 on groceries..."
```

**Key Points**:
- No tool calling (read-only operation)
- Vector similarity search for retrieval
- LLM grounded in retrieved context
- Citations for transparency

---

### Flow 3: PDF vs App Comparison

```
User: "Compare my PDF with tracked expenses"
  ‚Üì
[Intent Router] ‚Üí RAG_COMPARE
  ‚Üì
[RAG Compare Handler]
  ‚Üì
  [1. Extract PDF Expenses]
    - getAllChunks() ‚Üí user-filtered
    - Parse expenses from chunks
  ‚Üì
  [2. Fetch App Expenses]
    - GET /api/expenses via backend client
  ‚Üì
  [3. Normalize Both Datasets]
    - Date format: YYYY-MM-DD
    - Amount: float
    - Description: lowercase
  ‚Üì
  [4. Compute Diff (Code-based)]
    - Match by amount + date + description similarity
    - Output:
      * matched: []
      * pdf_only: []
      * app_only: []
      * summary: {}
  ‚Üì
  [5. LLM Explanation (Optional)]
    - Generate natural language summary
  ‚Üì
[Response] ‚Üê Structured diff OR explained summary
```

**Key Points**:
- **Diff is computed in code, NOT by LLM**
- LLM only explains results (interpretation layer)
- Deterministic comparison logic
- Can return structured or explained output

---

### Flow 4: Sync/Reconcile (Full Workflow)

```
User: "Sync my PDF expenses and generate report"
  ‚Üì
[Intent Router] ‚Üí SYNC_RECONCILE
  ‚Üì
[Sync/Reconcile Handler]
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 1: COMPARE                             ‚îÇ
‚îÇ ‚Ä¢ Call handleRagCompare(returnStructured)    ‚îÇ
‚îÇ ‚Ä¢ Get: {matched, pdf_only, app_only}         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 2: PLAN (Deterministic)                ‚îÇ
‚îÇ ‚Ä¢ Validate each pdf_only expense             ‚îÇ
‚îÇ ‚Ä¢ Validate each app_only expense             ‚îÇ
‚îÇ ‚Ä¢ Generate plan:                             ‚îÇ
‚îÇ   - to_app: [expenses to add via MCP]        ‚îÇ
‚îÇ   - to_pdf: [expenses to add to PDF]         ‚îÇ
‚îÇ ‚Ä¢ Log plan                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 3: VALIDATE                            ‚îÇ
‚îÇ ‚Ä¢ Check user has PDFs                        ‚îÇ
‚îÇ ‚Ä¢ Check plan non-empty                       ‚îÇ
‚îÇ ‚Ä¢ Check auth token valid                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 4: EXECUTE                             ‚îÇ
‚îÇ For each expense in to_app:                  ‚îÇ
‚îÇ   ‚Ä¢ Call create_expense MCP tool             ‚îÇ
‚îÇ   ‚Ä¢ Log result (success/error)               ‚îÇ
‚îÇ   ‚Ä¢ Continue on partial failure              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 5: REPORT                              ‚îÇ
‚îÇ ‚Ä¢ Generate HTML/CSV report                   ‚îÇ
‚îÇ ‚Ä¢ Include synced expenses + summary          ‚îÇ
‚îÇ ‚Ä¢ Save to data/reports/synced_XXX.html       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STAGE 6: RESPOND                             ‚îÇ
‚îÇ ‚Ä¢ "‚úÖ Synced N expenses to app"              ‚îÇ
‚îÇ ‚Ä¢ "üìÑ Report: /ai/reports/XXXXX.html"        ‚îÇ
‚îÇ ‚Ä¢ Include any errors                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Points**:
- Multi-stage orchestration
- **No LLM decides what to sync** (deterministic planner)
- Graceful partial failure handling
- Audit trail via reports
- Additive-only (never deletes)

---

## Custom ‚Üí Framework Mapping

| **Custom Component** | **LangChain/LangGraph Equivalent** | **Notes** |
|----------------------|-----------------------------------|-----------|
| **Intent Router** | LangGraph conditional routing node | Currently uses LLM classification ‚Üí Can be a router node with LLM-based edge selection |
| **Transactional Handler** | LangGraph workflow with tool-calling node | Single-stage workflow: route ‚Üí agent ‚Üí tools ‚Üí respond |
| **LLM Agent (agent.js)** | `create_react_agent()` or custom LangGraph loop | Implements tool-calling loop with max iterations |
| **MCP Tools** | LangChain `@langchain/core/tools` | Each tool becomes a `StructuredTool` with validation |
| **System Prompt** | LangChain `ChatPromptTemplate` | Structured prompt with variables (date, instructions, etc.) |
| **RAG Chunking** | `RecursiveCharacterTextSplitter` | LangChain's semantic splitter with overlap |
| **Embeddings** | `OpenAIEmbeddings` | Direct 1:1 mapping |
| **Vector Store** | LangChain vector store (in-memory or Faiss) | Replace custom JSON with LangChain vector abstraction |
| **RAG Retrieval** | `VectorStoreRetriever` | Built-in similarity search with top-k |
| **RAG Generation** | RetrievalQA chain or custom chain | Prompt + context + LLM |
| **Comparison Engine** | Standalone utility (keep as-is) | No framework needed - pure JS logic |
| **Reconciliation Planner** | LangGraph multi-step workflow | Graph with nodes: compare ‚Üí plan ‚Üí validate ‚Üí execute ‚Üí report |
| **Logging** | LangSmith tracing | Automatic tracing of all steps |
| **Error Handling** | LangChain error callbacks | Built-in error propagation |
| **Cost Tracking** | LangSmith usage tracking | Automatic token counting |
| **Backend Client** | Remain as utility | No change - HTTP client stays |

---

## Component Deep Dive

### 1. Intent Router

**Current Implementation**:
```javascript
// Uses LLM to classify intent
const intent = await classifyIntent(userMessage);
// Routes to appropriate handler
switch(intent) {
  case 'TRANSACTIONAL': return handleTransactional(...);
  case 'RAG_QA': return handleRagQA(...);
  ...
}
```

**LangGraph Equivalent**:
```javascript
// Define routing logic as conditional edge
const workflow = new StateGraph({
  channels: {
    intent: { reducer: (x) => x },
    message: { reducer: (x) => x },
    response: { reducer: (x) => x }
  }
});

// Classification node
workflow.addNode("classify_intent", classifyIntentNode);

// Handler nodes
workflow.addNode("transactional", transactionalNode);
workflow.addNode("rag_qa", ragQaNode);
workflow.addNode("rag_compare", ragCompareNode);
workflow.addNode("sync_reconcile", syncReconcileNode);

// Conditional routing
workflow.addConditionalEdges(
  "classify_intent",
  (state) => state.intent, // Route based on intent
  {
    "TRANSACTIONAL": "transactional",
    "RAG_QA": "rag_qa",
    "RAG_COMPARE": "rag_compare",
    "SYNC_RECONCILE": "sync_reconcile"
  }
);
```

**Why LangGraph is Better Here**:
- ‚úÖ Visualization of routing logic
- ‚úÖ Built-in state management
- ‚úÖ Easier to add new intents
- ‚úÖ Automatic tracing via LangSmith

---

### 2. MCP Tools

**Current Implementation**:
```javascript
// ai/src/mcp/tools/createExpense.js
export const createExpenseTool = {
  definition: {
    type: "function",
    function: {
      name: "create_expense",
      description: "Creates a new expense",
      parameters: {
        type: "object",
        properties: {
          amount: { type: "number" },
          category: { type: "string" },
          ...
        },
        required: ["amount"]
      }
    }
  },
  run: async (args, token) => {
    // Validate, call backend API, return result
  }
};
```

**LangChain Equivalent**:
```javascript
import { StructuredTool } from "@langchain/core/tools";
import { z } from "zod";

class CreateExpenseTool extends StructuredTool {
  name = "create_expense";
  description = "Creates a new expense in the tracker";
  
  schema = z.object({
    amount: z.number().positive().describe("Expense amount"),
    category: z.string().describe("Expense category"),
    description: z.string().optional(),
    date: z.string().optional()
  });
  
  async _call(input) {
    // Validation happens automatically via zod
    // Call backend API
    // Return result
  }
}
```

**Why LangChain is Better Here**:
- ‚úÖ Built-in zod validation
- ‚úÖ Automatic OpenAI function schema conversion
- ‚úÖ Better TypeScript/type safety
- ‚úÖ Integrates with LangSmith for automatic tracing

---

### 3. RAG Pipeline

**Current Implementation**:
```javascript
// Upload: PDF ‚Üí Extract ‚Üí Chunk ‚Üí Embed ‚Üí Store
const text = await extractText(pdf);
const chunks = chunkText(text);
const embeddings = await generateEmbeddings(chunks);
await storeInVectorDB(embeddings);

// Query: Question ‚Üí Embed ‚Üí Search ‚Üí Generate
const queryEmbedding = await generateEmbedding(question);
const results = await searchSimilar(queryEmbedding);
const answer = await llm.generate(prompt + context);
```

**LangChain Equivalent**:
```javascript
// Upload: Use document loaders + text splitters
import { PDFLoader } from "langchain/document_loaders/fs/pdf";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import { OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "langchain/vectorstores/memory";

const loader = new PDFLoader(pdfPath);
const docs = await loader.load();

const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 500,
  chunkOverlap: 50
});
const chunks = await splitter.splitDocuments(docs);

const embeddings = new OpenAIEmbeddings();
const vectorStore = await MemoryVectorStore.fromDocuments(chunks, embeddings);

// Query: Use retrieval chain
import { RetrievalQAChain } from "langchain/chains";

const chain = RetrievalQAChain.fromLLM(
  llm,
  vectorStore.asRetriever(5) // top 5 results
);

const response = await chain.call({ query: question });
```

**Why LangChain is Better Here**:
- ‚úÖ Pre-built document loaders (PDF, DOCX, etc.)
- ‚úÖ Multiple text splitter strategies
- ‚úÖ Vector store abstraction (easy to swap)
- ‚úÖ Built-in retrieval chains
- ‚úÖ Automatic source citation

---

### 4. Reconciliation Workflow

**Current Implementation**:
```javascript
// Sequential stages
const diff = await handleRagCompare(..., {returnStructured: true});
const plan = await createReconciliationPlan(diff);
await validatePrerequisites(plan);
const results = await executeSyncPlan(plan);
const report = await generateReport(results);
return summarize(report);
```

**LangGraph Equivalent**:
```javascript
// Define as state graph
const workflow = new StateGraph({
  channels: {
    diff: { reducer: (x) => x },
    plan: { reducer: (x) => x },
    results: { reducer: (x) => x },
    report: { reducer: (x) => x }
  }
});

workflow.addNode("compare", compareNode);
workflow.addNode("plan", planNode);
workflow.addNode("validate", validateNode);
workflow.addNode("execute", executeNode);
workflow.addNode("report", reportNode);

workflow.addEdge("compare", "plan");
workflow.addEdge("plan", "validate");
workflow.addConditionalEdges("validate", 
  (state) => state.validated ? "execute" : "error"
);
workflow.addEdge("execute", "report");
workflow.addEdge("report", END);

const app = workflow.compile();
```

**Why LangGraph is Better Here**:
- ‚úÖ Clear visualization of workflow
- ‚úÖ State propagation between stages
- ‚úÖ Built-in error handling paths
- ‚úÖ Checkpoint support (pause/resume)
- ‚úÖ LangSmith traces entire workflow

---

## Safety & Production Patterns

### Current Safety Mechanisms

| **Pattern** | **Implementation** | **LangChain/LangGraph Equivalent** |
|-------------|-------------------|-----------------------------------|
| **Max Tool Iterations** | `MAX_TOOL_ITERATIONS = 5` | Agent executor `max_iterations` |
| **LLM Timeout** | `LLM_TIMEOUT = 60000ms` | OpenAI client timeout config |
| **Max Response Tokens** | `MAX_RESPONSE_TOKENS = 500` | LLM `maxTokens` parameter |
| **Tool Argument Validation** | Custom JSON schema validator | Zod schema in `StructuredTool` |
| **Tool Execution Timeout** | `executeToolSafely()` with 30s timeout | LangChain callbacks + timeout wrapper |
| **Retry Logic** | Custom retry with exponential backoff | `@langchain/core` retry config |
| **Rate Limiting** | Express `express-rate-limit` | Keep as-is (middleware) |
| **User Isolation** | userId propagated through context | Add userId to state/metadata |
| **Cost Tracking** | Custom usage logger | LangSmith automatic tracking |
| **Structured Logging** | Winston-style logger with traceId | LangSmith traces |
| **Error Classification** | `errorClassification.js` | LangChain error callbacks |

### Safety Philosophy

**Core Principle**: **LLM for interpretation, Code for decisions**

| **Responsibility** | **LLM** | **Code** |
|-------------------|---------|----------|
| Intent understanding | ‚úÖ | ‚ùå |
| Natural language parsing | ‚úÖ | ‚ùå |
| Tool argument extraction | ‚úÖ | ‚ùå |
| **Financial decisions** | ‚ùå | ‚úÖ |
| **Data reconciliation** | ‚ùå | ‚úÖ |
| **Validation** | ‚ùå | ‚úÖ |
| **Execution** | ‚ùå | ‚úÖ |
| Explanation/summarization | ‚úÖ | ‚ùå |

**Why This Matters**:
- LLMs are probabilistic ‚Üí cannot be trusted with critical operations
- Business rules must be deterministic and version-controlled
- Audit compliance requires traceable logic
- Cost explosion risk if LLM makes recursive decisions

---

## Migration Strategy

### Phase 1: Foundation (Week 1)

**Goals**: 
- Set up LangChain/LangGraph/LangSmith environment
- Create equivalent tool wrappers
- Implement basic chat flow

**Tasks**:
1. Initialize `ai-langx/` with package.json
2. Install dependencies:
   - `@langchain/core`
   - `@langchain/openai`
   - `@langchain/langgraph`
   - `langsmith`
3. Create LangChain tools for all 5 MCP tools
4. Implement basic agent executor
5. Test single tool calling flow

**Success Criteria**:
- Can execute "add ‚Çπ500 for lunch" end-to-end
- LangSmith trace visible
- Tool validation working

---

### Phase 2: RAG Implementation (Week 2)

**Goals**:
- Implement RAG pipeline using LangChain components
- Achieve parity with existing RAG functionality

**Tasks**:
1. PDF loader + text splitter
2. Embeddings + vector store (in-memory first)
3. Retrieval QA chain
4. Comparison engine (keep existing code)
5. Test RAG queries

**Success Criteria**:
- Can upload PDF and query it
- Can compare PDF vs App expenses
- Results match existing implementation

---

### Phase 3: Workflows (Week 3)

**Goals**:
- Implement multi-stage workflows using LangGraph
- Reconciliation pipeline

**Tasks**:
1. Intent router as LangGraph conditional edges
2. Reconciliation workflow as state graph
3. Error handling paths
4. Partial failure recovery

**Success Criteria**:
- Can sync PDF expenses end-to-end
- Workflow visible in LangSmith
- Error scenarios handled gracefully

---

### Phase 4: Observability (Week 4)

**Goals**:
- Full LangSmith integration
- Production monitoring

**Tasks**:
1. Configure LangSmith traces for all flows
2. Add custom tags and metadata
3. Cost tracking dashboards
4. Performance analysis

**Success Criteria**:
- Every request traced in LangSmith
- Can debug failures from traces
- Cost per request visible

---

### Phase 5: Documentation (Week 5)

**Goals**:
- Create comprehensive comparison guide
- Educational resources

**Tasks**:
1. Write architecture comparison doc
2. Create flow diagrams (old vs new)
3. Document trade-offs
4. Write migration guide

**Success Criteria**:
- Clear guidance on when to use custom vs framework
- Diagrams explain both approaches
- Code is well-commented

---

## Key Takeaways

### When to Use Custom Implementation

‚úÖ **Use Custom When**:
- You need 100% control over execution flow
- Framework overhead is unacceptable
- Business logic is highly specific
- You want minimal dependencies
- You need fine-grained cost control

### When to Use LangChain/LangGraph

‚úÖ **Use Framework When**:
- You want rapid prototyping
- You need built-in observability
- You want community-tested components
- You'll swap LLM providers frequently
- You want automatic tracing
- Team is familiar with the framework

### Hybrid Approach (Recommended)

The best production systems often use **both**:
- LangChain/LangGraph for orchestration and RAG
- Custom code for critical business logic
- Keep deterministic operations out of LLM
- Use frameworks where they add value

**Example**:
```
LangGraph Workflow:
  ‚îú‚îÄ Node 1: Intent classification (LangChain agent)
  ‚îú‚îÄ Node 2: Execute tools (LangChain tools)
  ‚îú‚îÄ Node 3: Reconciliation logic (CUSTOM CODE - no LLM)
  ‚îî‚îÄ Node 4: Generate report (LangChain chain)
```

---

## Next Steps

1. ‚úÖ Complete this analysis document
2. üîÑ Design ai-langx/ folder structure
3. üîÑ Implement Phase 1: Foundation
4. üîÑ Implement Phase 2: RAG
5. üîÑ Implement Phase 3: Workflows
6. üîÑ Add LangSmith integration
7. üîÑ Write comparison documentation

Ready to proceed with implementation! üöÄ
